# ğŸ›ï¸ Law Advisor Scrapper

A Python-based system for extracting, structuring, and formatting Canadian employment and labor legislation. Supports CLI, REST API, Kafka events, and asynchronous scraping.

---

## ğŸš€ Features

- âš¡ Asynchronous crawling with Crawl4AI
- ğŸ“¦ Structured output (JSON + Markdown)
- ğŸ–¥ï¸ CLI for law-by-law scraping
- ğŸŒ REST API (FastAPI) with Kafka integration
- ğŸ³ Docker-compatible
- ğŸ§ª Unit tested

---

## ğŸ“ Project Structure

```
legislative_crawler/
â”œâ”€â”€ cli/                  # CLI interface
â”œâ”€â”€ api/                  # FastAPI endpoints
â”œâ”€â”€ crawlers/             # Province-specific crawlers
â”œâ”€â”€ kafka/                # Kafka consumer & producer
â”œâ”€â”€ config/               # App + Kafka configuration
â”œâ”€â”€ resources/            # links.json with legislation metadata
â”œâ”€â”€ utils/                # Logging, helpers
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ scraper_lambda.py     # Kafka Lambda entrypoint
â”œâ”€â”€ requirements.txt      # All dependencies
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ğŸ§° Installation

### âœ… Prerequisites

- Python 3.10+
- Kafka (locally or via Docker)
- Docker (optional)
- Git

### ğŸ§± Local Setup

```bash
git clone https://github.com/yourusername/legislative-crawler.git
cd legislative-crawler

# Create and activate virtual env
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
python -m playwright install
```

---

## ğŸ”„ Usage

### ğŸ–¥ CLI Mode

```bash
# Crawl a specific law
python -m legislative_crawler.main FED_CLC

# Crawl all laws in a province
python -m legislative_crawler.main ON
```

### ğŸŒ API Mode

```bash
python -m legislative_crawler.main api
```

API available at: `http://localhost:8000`

#### Endpoints

- `POST /crawl` â†’ Start crawl
- `GET /crawl/{task_id}` â†’ Get crawl status
- `GET /health` â†’ Check if API is alive

---

## âš™ï¸ Kafka Lambda Scraper

Start a Kafka-based listener that reacts to province names and returns crawl results:

```bash
python scraper_lambda.py
```

**Send province names** (e.g., `ontario`, `ON`, `fed`) to topic: `scraper-requests`.

**Responses** are sent to topic: `scraper-responses`.

---

## ğŸ‹ Docker Setup

```bash
docker build -t legislative-crawler .
docker run -p 8000:8000 legislative-crawler
```

---

## âš™ï¸ Configuration

Available via environment variables:

| Variable | Purpose |
|----------|---------|
| `KAFKA_BOOTSTRAP_SERVERS` | e.g. `localhost:9092` |
| `KAFKA_REQUEST_TOPIC`     | Kafka input topic |
| `KAFKA_RESPONSE_TOPIC`    | Kafka output topic |
| `KAFKA_CONSUMER_GROUP`    | Kafka group ID |
| `LINKS_FILE`              | Path to links.json |
| `API_HOST`, `API_PORT`, `API_RELOAD` | FastAPI settings |

---

## ğŸ§ª Testing

```bash
pytest tests/
```

---

## â• Add New Province

1. Add alias in `CrawlerRouter.PROVINCE_ALIAS`
2. Implement a crawler in `crawlers/{province}.py`
3. Add laws to `resources/links.json`

---

## ğŸ“„ Output Format

### JSON

```json
{
  "province": "ON",
  "status": "success",
  "pages": [
    {
      "identifier": "ON_ESA",
      "markdown": "...",
      "status": "success"
    }
  ]
}
```

### Markdown

Markdown is extracted, pruned, and formatted per law page.

---

## ğŸ§¹ Troubleshooting

| Problem | Solution |
|--------|----------|
| `BrowserType.launch` error | Run `python -m playwright install` |
| Kafka group error | Ensure Kafka is running locally |
| Province not found | Normalize to uppercase / alias format |
| Empty responses | Check `links.json` and topic messages |

---

## ğŸ“œ License

MIT License â€“ see `LICENSE` file.

---

Let me know if you want a `.env` file template or Docker Compose setup included!